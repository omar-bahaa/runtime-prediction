{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "_kg_hide-output": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-09-09T07:36:26.924458Z",
          "iopub.status.busy": "2023-09-09T07:36:26.924088Z",
          "iopub.status.idle": "2023-09-09T07:36:38.418205Z",
          "shell.execute_reply": "2023-09-09T07:36:38.417039Z",
          "shell.execute_reply.started": "2023-09-09T07:36:26.92443Z"
        },
        "id": "GP4hQuu98xGG",
        "outputId": "1cfbe39b-5bc9-44ec-afd6-41ed97485d78",
        "papermill": {
          "duration": 264.245878,
          "end_time": "2023-09-01T16:55:11.276628",
          "exception": false,
          "start_time": "2023-09-01T16:50:47.03075",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n!pip install numpy\\n!pip install pandas\\n!pip install tqdm\\n!pip install scikit-learn\\n!pip install torch\\n!pip install torch-geometric\\n!pip install timm\\n!pip install matplotlib\\n'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## if you have not installed those necessary packages, please install them;\n",
        "\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install tqdm\n",
        "!pip install scikit-learn\n",
        "!pip install torch\n",
        "!pip install torch-geometric\n",
        "!pip install timm\n",
        "!pip install matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-09T07:36:38.421299Z",
          "iopub.status.busy": "2023-09-09T07:36:38.42085Z",
          "iopub.status.idle": "2023-09-09T07:36:38.429449Z",
          "shell.execute_reply": "2023-09-09T07:36:38.428331Z",
          "shell.execute_reply.started": "2023-09-09T07:36:38.421257Z"
        },
        "id": "sHZ1wY988xGH",
        "papermill": {
          "duration": 4.819384,
          "end_time": "2023-09-01T16:55:16.104784",
          "exception": false,
          "start_time": "2023-09-01T16:55:11.2854",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "import sklearn,sklearn.model_selection\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "\n",
        "from torch_geometric.nn import GCNConv,SAGEConv,SGConv,TAGConv,ARMAConv,\\\n",
        "ChebConv,GENConv,LEConv,GATConv,MFConv,FeaStConv,GATv2Conv,\\\n",
        "GraphConv,ResGatedGraphConv,ClusterGCNConv\n",
        "\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from timm.scheduler import CosineLRScheduler\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "execution": {
          "iopub.execute_input": "2023-09-09T07:36:38.431491Z",
          "iopub.status.busy": "2023-09-09T07:36:38.430664Z",
          "iopub.status.idle": "2023-09-09T07:37:03.099175Z",
          "shell.execute_reply": "2023-09-09T07:37:03.097977Z",
          "shell.execute_reply.started": "2023-09-09T07:36:38.431465Z"
        },
        "id": "1dopI7288xGI",
        "outputId": "1f85fcad-cf12-4d6b-b069-1ff3cf307c93",
        "papermill": {
          "duration": 0.020227,
          "end_time": "2023-09-01T16:55:16.152594",
          "exception": false,
          "start_time": "2023-09-01T16:55:16.132367",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# involving dataset\n",
        "def load_df(directory):\n",
        "    splits = [\"train\", \"valid\", \"test\"]\n",
        "    dfs = dict()\n",
        "\n",
        "    for split in splits:\n",
        "        path = os.path.join(directory, split)\n",
        "        files = os.listdir(path)\n",
        "        list_df = []\n",
        "\n",
        "        for file in files:\n",
        "            d = dict(np.load(os.path.join(path,file)))\n",
        "            d['file'] = file\n",
        "            list_df.append(d)\n",
        "        dfs[split] = pd.DataFrame.from_dict(list_df)\n",
        "    return dfs\n",
        "\n",
        "## please make sure the path to the npz_all is correct;\n",
        "tile_xla = load_df('./tile/xla/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgqTc3Fh8xGI",
        "papermill": {
          "duration": 0.008874,
          "end_time": "2023-09-01T16:56:21.968592",
          "exception": false,
          "start_time": "2023-09-01T16:56:21.959718",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Define Dataset and Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-09T07:37:03.102254Z",
          "iopub.status.busy": "2023-09-09T07:37:03.101875Z",
          "iopub.status.idle": "2023-09-09T07:37:03.110811Z",
          "shell.execute_reply": "2023-09-09T07:37:03.109656Z",
          "shell.execute_reply.started": "2023-09-09T07:37:03.102219Z"
        },
        "id": "okwhcQAX8xGJ",
        "papermill": {
          "duration": 0.020329,
          "end_time": "2023-09-01T16:56:21.997734",
          "exception": false,
          "start_time": "2023-09-01T16:56:21.977405",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# class of dataset (for generation)\n",
        "class TileDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        config_feat = torch.tensor(row['config_feat'].astype(np.float32))\n",
        "        node_feat = torch.tensor(row['node_feat'].astype(np.float32))\n",
        "        node_opcode = torch.tensor(row['node_opcode'].astype(np.int64))\n",
        "        edge_index = torch.tensor(np.swapaxes(row['edge_index'],0,1).astype(np.int64))\n",
        "        target = (row['config_runtime']/(row['config_runtime_normalizers']+1e-5)).astype(np.float32) #/row['config_runtime_normalizers']\n",
        "        # minmax scale the target, we only care about order\n",
        "        target = (target - np.mean(target)) / (np.std(target) + 1e-5)\n",
        "\n",
        "        target = torch.tensor(target)\n",
        "        return config_feat, node_feat, node_opcode, edge_index, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-09T07:37:03.112971Z",
          "iopub.status.busy": "2023-09-09T07:37:03.112301Z",
          "iopub.status.idle": "2023-09-09T07:37:03.12813Z",
          "shell.execute_reply": "2023-09-09T07:37:03.127217Z",
          "shell.execute_reply.started": "2023-09-09T07:37:03.112936Z"
        },
        "id": "yvU79AAJ8xGK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, conv_layer:str='sageconv'):\n",
        "        super().__init__()\n",
        "\n",
        "        conv_substitute = ['sageconv','gcnconv','sgconv'\\\n",
        "                  ,'tagconv','chebconv','armaconv','gatv2conv'\\\n",
        "                  ,'genconv','leconv','gatconv','clustergcnconv'\\\n",
        "                  ,'graphconv','resgatedgraphconv','mfconv','feastconv','mlp']\n",
        "        assert conv_layer.lower() in conv_substitute, 'choose convolution layer in:'+str(conv_substitute)\n",
        "\n",
        "        if conv_layer.lower() == 'sageconv':\n",
        "          conv = SAGEConv\n",
        "        elif conv_layer.lower() == 'gcnconv':\n",
        "          conv = GCNConv\n",
        "        elif conv_layer.lower() == 'sgconv':\n",
        "          conv = SGConv\n",
        "        elif conv_layer.lower() == 'tagconv':\n",
        "          conv = TAGConv\n",
        "        elif conv_layer.lower() == 'chebconv':\n",
        "          conv = ChebConv\n",
        "        elif conv_layer.lower() == 'genconv':\n",
        "          conv = GENConv\n",
        "        elif conv_layer.lower() == 'leconv':\n",
        "          conv = LEConv\n",
        "        elif conv_layer.lower() == 'gatconv':\n",
        "          conv = GATConv\n",
        "        elif conv_layer.lower() == 'gatv2conv':\n",
        "          conv = GATv2Conv\n",
        "        elif conv_layer.lower() == 'graphconv':\n",
        "          conv = GraphConv\n",
        "        elif conv_layer.lower() == 'resgatedgraphconv':\n",
        "          conv = ResGatedGraphConv\n",
        "        elif conv_layer.lower() == 'clustergcnconv':\n",
        "          conv = ClusterGCNConv\n",
        "        elif conv_layer.lower() == 'armaconv':\n",
        "          conv = ARMAConv\n",
        "        elif conv_layer.lower() == 'mfconv':\n",
        "          conv = MFConv\n",
        "        elif conv_layer.lower() == 'feastconv':\n",
        "          conv = FeaStConv\n",
        "        elif conv_layer.lower() == 'mlp':\n",
        "          conv = nn.Linear\n",
        "\n",
        "        self.conv_layer = conv_layer.lower()\n",
        "\n",
        "        op_embedding_dim = 12\n",
        "        hidden_dim = 256\n",
        "        dropout = 0.4\n",
        "\n",
        "        self.embedding = nn.Embedding(120, op_embedding_dim)\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(op_embedding_dim + 140, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        in_channels = hidden_dim\n",
        "        hidden_channels = [128, 256, 512, 256, 128]\n",
        "        graph_out = 86\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "\n",
        "        if conv_layer.lower() in ['chebconv','armaconv','feastconv']:\n",
        "          self.convs.append(conv(in_channels, hidden_channels[0], 3))\n",
        "          for i in range(1, len(hidden_channels)):\n",
        "              self.convs.append(conv(hidden_channels[i-1], hidden_channels[i], 3))\n",
        "          self.convs.append(conv(hidden_channels[-1], graph_out, 3))\n",
        "        else:\n",
        "          self.convs.append(conv(in_channels, hidden_channels[0]))\n",
        "          for i in range(1, len(hidden_channels)):\n",
        "              self.convs.append(conv(hidden_channels[i-1], hidden_channels[i]))\n",
        "          self.convs.append(conv(hidden_channels[-1], graph_out))\n",
        "\n",
        "        self.dense = nn.Sequential(\n",
        "            nn.Linear(graph_out*2 + 24, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=dropout/2),\n",
        "            nn.Linear(hidden_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cfg, x_feat, x_op, edge_index):\n",
        "        x = torch.cat([x_feat, self.embedding(x_op)], dim=1)\n",
        "        x = self.ffn(x)\n",
        "\n",
        "        if self.conv_layer == 'mlp':\n",
        "          for conv in self.convs:\n",
        "            x = conv(x).relu()\n",
        "        else:\n",
        "          for conv in self.convs:\n",
        "            x = conv(x, edge_index).relu()\n",
        "\n",
        "        x_mean = x.mean(dim=0)\n",
        "        x_max = x.max(dim=0).values\n",
        "\n",
        "        x = torch.cat([x_cfg, x_max.repeat(len(x_cfg), 1), x_mean.repeat(len(x_cfg), 1)], dim=1)\n",
        "        x = torch.flatten(self.dense(x))\n",
        "        x = (x - torch.mean(x)) / (torch.std(x) + 1e-5)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-09T07:37:03.129894Z",
          "iopub.status.busy": "2023-09-09T07:37:03.129534Z",
          "iopub.status.idle": "2023-09-09T07:37:03.143752Z",
          "shell.execute_reply": "2023-09-09T07:37:03.142812Z",
          "shell.execute_reply.started": "2023-09-09T07:37:03.129839Z"
        },
        "id": "kUDmUSyp8xGK",
        "papermill": {
          "duration": 0.021726,
          "end_time": "2023-09-01T16:56:22.11899",
          "exception": false,
          "start_time": "2023-09-01T16:56:22.097264",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "## we follow the similar setting provided by the competition, combine the train-valid to be training set.\n",
        "train_df = tile_xla[\"train\"]\n",
        "test_df = pd.concat((tile_xla[\"valid\"], tile_xla[\"test\"]), axis=0).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "execution": {
          "iopub.execute_input": "2023-09-09T07:37:03.147294Z",
          "iopub.status.busy": "2023-09-09T07:37:03.147009Z",
          "iopub.status.idle": "2023-09-09T07:37:58.480733Z",
          "shell.execute_reply": "2023-09-09T07:37:58.478944Z",
          "shell.execute_reply.started": "2023-09-09T07:37:03.147271Z"
        },
        "id": "9QMjL2L38xGK",
        "outputId": "67799cc1-82e0-47ed-cfae-38d7c54f910a",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "average testing loss: 0.6201\n"
          ]
        }
      ],
      "source": [
        "# dataset split: unnecessary when follow the competition\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
        "\n",
        "conv_layer = 'gcnconv'\n",
        "\n",
        "## model\n",
        "model = Model(conv_layer=conv_layer).to(device)\n",
        "\n",
        "## retrain?\n",
        "retrain_mark = False\n",
        "\n",
        "## loss function;\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "if os.path.exists(f'./save_model/tile/{conv_layer}.pth') and (retrain_mark==False):\n",
        "    ## load model;\n",
        "    model.load_state_dict(torch.load(f'./save_model/tile/{conv_layer}.pth'))\n",
        "else:\n",
        "    ## retrain;\n",
        "    train_dataset = TileDataset(train_df)\n",
        "    steps = len(train_dataset) * 20\n",
        "    warmup_steps = int(steps * 0.2)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    scheduler = CosineLRScheduler(optimizer, t_initial=steps, warmup_t=warmup_steps, warmup_lr_init=1e-6, lr_min=2e-8)\n",
        "\n",
        "    ## loss per epoch;\n",
        "    epoch_training_loss = []\n",
        "\n",
        "    ## runtime collections:1\n",
        "    start = time.time()\n",
        "\n",
        "    ## training\n",
        "    for epoch in range(20):\n",
        "        ##\n",
        "        model.train()\n",
        "        pbar = tqdm(range(len(train_dataset)), leave=False)\n",
        "        loss_sum = 0\n",
        "        n = 0\n",
        "        for i in range(len(train_dataset)):\n",
        "            cfg_ft, nd_ft, nd_op, ind, target = [x.to(device) for x in train_dataset[i]]\n",
        "            out = model(cfg_ft, nd_ft, nd_op, ind)\n",
        "            loss = criterion(out, target)\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1e-2)\n",
        "            scheduler.step(i + len(train_dataset) * epoch)\n",
        "            optimizer.step()\n",
        "            loss_sum += loss.item()\n",
        "            n += 1\n",
        "\n",
        "            if n % 10 == 0:\n",
        "                pbar.set_description(f'running loss: {(loss_sum/n):.4f}, current loss: {(loss.item()):.4f}')\n",
        "\n",
        "        epoch_training_loss.append(loss_sum/n)\n",
        "\n",
        "        pbar.close()\n",
        "\n",
        "        print(f'epoch: {epoch}, average training loss: {epoch_training_loss[-1]:.4f}')\n",
        "\n",
        "    ## runtime collections:2\n",
        "    end = time.time()\n",
        "    runtime = (end - start) / 60\n",
        "    print(f'total training time = {runtime:.4f} minutes.')\n",
        "\n",
        "# testing\n",
        "test_dataset = TileDataset(test_df)\n",
        "model.eval()\n",
        "tile_xla_predictions = []\n",
        "testing_loss = 0\n",
        "n = 0\n",
        "for i in range(len(test_dataset)):\n",
        "    cfg_ft, nd_ft, nd_op, ind, target = [x.to(device) for x in test_dataset[i]]\n",
        "    out = model(cfg_ft, nd_ft, nd_op, ind)\n",
        "    loss = criterion(out, target)\n",
        "    testing_loss += loss.item()\n",
        "    n += 1\n",
        "\n",
        "testing_loss = testing_loss/n\n",
        "\n",
        "## output the overall loss:\n",
        "if os.path.exists(f'./save_model/tile/{conv_layer}.pth') and (retrain_mark==False):\n",
        "    pass\n",
        "else:\n",
        "    ## trained model saved;\n",
        "    torch.save(model.state_dict(), f'./save_model/tile/{conv_layer}.pth')\n",
        "\n",
        "    print(\"epoch: \", list(range(20)))\n",
        "    print(\"epoch-based average training loss: \", epoch_training_loss)\n",
        "\n",
        "print(f'average testing loss: {testing_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-09T07:37:58.48188Z",
          "iopub.status.idle": "2023-09-09T07:37:58.482464Z",
          "shell.execute_reply": "2023-09-09T07:37:58.482209Z",
          "shell.execute_reply.started": "2023-09-09T07:37:58.482181Z"
        },
        "id": "81etRnUZ8xGL",
        "papermill": {
          "duration": 42.864288,
          "end_time": "2023-09-01T19:31:46.765649",
          "exception": false,
          "start_time": "2023-09-01T19:31:03.901361",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1520/1520 [00:37<00:00, 40.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "score max: 0.9717964480487458, score mean: 1.0040181484900816\n"
          ]
        }
      ],
      "source": [
        "# evaluation function\n",
        "def score_tile_mean(predictions, df):\n",
        "    score = 0\n",
        "    for i in range(len(df)):\n",
        "        predbest = np.mean(df.iloc[i]['config_runtime'][predictions[i]])\n",
        "        best = np.mean(np.sort(df.iloc[i]['config_runtime'])[:50])\n",
        "\n",
        "        ## zero avoider;\n",
        "        if best==0:\n",
        "            best +=0.01\n",
        "        if predbest==0:\n",
        "            predbest +=0.01\n",
        "            \n",
        "        score += 2 - predbest / best\n",
        "    score /= len(df)\n",
        "    return score\n",
        "def score_tile_max(predictions, df):\n",
        "    score = 0\n",
        "    for i in range(len(df)):\n",
        "        predbest = np.min(df.iloc[i]['config_runtime'][predictions[i][:5]])\n",
        "        best = np.min(df.iloc[i]['config_runtime'])\n",
        "\n",
        "        ## zero avoider;\n",
        "        if best==0:\n",
        "            best +=0.01\n",
        "        if predbest==0:\n",
        "            predbest +=0.01\n",
        "            \n",
        "        score += 2 - predbest/best\n",
        "    score /= len(df)\n",
        "    return score\n",
        "\n",
        "tile_xla_predictions = [[] for i in range(len(test_dataset))]\n",
        "\n",
        "model.eval()\n",
        "pbar = tqdm(range(len(test_dataset)))\n",
        "\n",
        "for i in pbar:\n",
        "    cfg_ft, nd_ft, nd_op, ind, target = (x.to(device) for x in test_dataset[i])\n",
        "    out = model(cfg_ft, nd_ft, nd_op, ind)\n",
        "    tile_xla_predictions[i].append(out.cpu().detach().numpy())\n",
        "\n",
        "tile_xla_predictions = [np.argsort(np.mean(pred,axis=0))[:5] for pred in tile_xla_predictions]\n",
        "\n",
        "print(f'score max: {score_tile_max(tile_xla_predictions,test_df)}, score mean: {score_tile_mean(tile_xla_predictions,test_df)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-09T07:37:58.484696Z",
          "iopub.status.idle": "2023-09-09T07:37:58.488703Z",
          "shell.execute_reply": "2023-09-09T07:37:58.488536Z",
          "shell.execute_reply.started": "2023-09-09T07:37:58.488517Z"
        },
        "id": "l10x6nsJ8xGL",
        "papermill": {
          "duration": 20.880172,
          "end_time": "2023-09-01T19:32:28.307392",
          "exception": false,
          "start_time": "2023-09-01T19:32:07.42722",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# sub = pd.read_csv('/kaggle/input/predict-ai-model-runtime/sample_submission.csv')\n",
        "# for i,filename in enumerate(tile_xla[\"test\"]['file'].values):\n",
        "#     id = 'tile:xla:' + filename[:-4]\n",
        "#     sub.loc[sub.ID == id,'TopConfigs'] = ';'.join(tile_xla_predictions[i].astype(str))\n",
        "# sub.to_csv('submission.csv',index=False)\n",
        "# sub"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 9735.485807,
      "end_time": "2023-09-01T19:32:52.176348",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-09-01T16:50:36.690541",
      "version": "2.4.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
